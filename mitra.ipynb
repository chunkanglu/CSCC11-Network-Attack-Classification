{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49af8a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chunkanglu/Documents/School/Fall 2025/CSCC11/Project/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6c02d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "DATA_PATH = \"data/\"\n",
    "DATA_FILE = \"processed_traffic.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d298abf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_parquet(DATA_PATH + DATA_FILE)\n",
    "# X, y = data.drop(columns=[\"Label\", \"Attack Name\"]), data[\"Label\"]\n",
    "data_train, data_test = train_test_split(data, test_size=0.1, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b66b8575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((560, 49), (62, 49))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_smol = data_train.sample(frac=0.01, random_state=RANDOM_SEED)\n",
    "data_test_smol = data_test.sample(frac=0.01, random_state=RANDOM_SEED)\n",
    "data_train_smol.shape, data_test_smol.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2836030b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((55960, 47), (6218, 47), (55960,), (6218,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f18ca9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TabularDataset(data_train)\n",
    "test_dataset = TabularDataset(data_test)\n",
    "train_dataset_smol = TabularDataset(data_train_smol)\n",
    "test_dataset_smol = TabularDataset(data_test_smol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f353097e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20251125_022352\"\n",
      "Preset alias specified: 'medium' maps to 'medium_quality'.\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.11.13\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #202403110203~1715181801~22.04~aba43ee SMP PREEMPT_DYNAMIC Wed M\n",
      "CPU Count:          12\n",
      "Memory Avail:       3.96 GB / 15.46 GB (25.6%)\n",
      "Disk Space Avail:   384.91 GB / 911.02 GB (42.3%)\n",
      "===================================================\n",
      "Presets specified: ['medium']\n",
      "Beginning AutoGluon training ... Time limit = 60s\n",
      "AutoGluon will save models to \"/home/chunkanglu/Documents/School/Fall 2025/CSCC11/Project/AutogluonModels/ag-20251125_022352\"\n",
      "Train Data Rows:    560\n",
      "Train Data Columns: 48\n",
      "Label Column:       Label\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    4036.89 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.24 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['Attack Name']\n",
      "\t\t\tRemoving text_ngram feature due to error: '__nlp__'\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 2): ['CWR Flag Count', 'ECE Flag Count']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])        : 28 | ['Total Length of Fwd Packet', 'Total Length of Bwd Packet', 'Fwd Packet Length Mean', 'Fwd Packet Length Std', 'Bwd Packet Length Mean', ...]\n",
      "\t\t('int', [])          : 17 | ['Src Port', 'Dst Port', 'Flow Duration', 'Total Fwd Packet', 'Total Bwd packets', ...]\n",
      "\t\t('object', ['text']) :  1 | ['Attack Name']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', ['text_as_category'])  :  1 | ['Attack Name']\n",
      "\t\t('float', [])                       : 28 | ['Total Length of Fwd Packet', 'Total Length of Bwd Packet', 'Fwd Packet Length Mean', 'Fwd Packet Length Std', 'Bwd Packet Length Mean', ...]\n",
      "\t\t('int', [])                         : 16 | ['Src Port', 'Dst Port', 'Flow Duration', 'Total Fwd Packet', 'Total Bwd packets', ...]\n",
      "\t\t('int', ['binned', 'text_special']) :  5 | ['Attack Name.char_count', 'Attack Name.word_count', 'Attack Name.capital_ratio', 'Attack Name.lower_ratio', 'Attack Name.symbol_ratio. ']\n",
      "\t\t('int', ['bool'])                   :  1 | ['Fwd PSH Flags']\n",
      "\t0.3s = Fit runtime\n",
      "\t46 features in original data used to generate 51 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.19 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.34s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 448, Val Rows: 112\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'MITRA': [{'fine_tune': False, 'ag_args_fit': {'num_gpus': 1}}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: Mitra ... Training model for up to 59.66s of the 59.66s of remaining time.\n",
      "\tWarning: Not enough memory to safely train model. Estimated to require 7.278 GB out of 3.947 GB available memory (184.370%)... (90.000% of avail memory is the max safe size)\n",
      "\tTo force training the model, specify the model hyperparameter \"ag.max_memory_usage_ratio\" to a larger value (currently 1.0, set to >=2.10 to avoid the error)\n",
      "\t\tTo set the same value for all models, do the following when calling predictor.fit: `predictor.fit(..., ag_args_fit={\"ag.max_memory_usage_ratio\": VALUE})`\n",
      "\t\tSetting \"ag.max_memory_usage_ratio\" to values above 1 may result in out-of-memory errors. You may consider using a machine with more memory as a safer alternative.\n",
      "\tNot enough memory to train Mitra... Skipping this model.\n",
      "No base models to train on, skipping auxiliary stack level 2...\n",
      "Warning: AutoGluon did not successfully train any models\n",
      "AutoGluon training complete, total runtime = 0.48s ... Best model: None\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "No models were trained successfully during fit(). Inspect the log output or increase verbosity to determine why no models were fit. Alternatively, set `raise_on_no_models_fitted` to False during the fit call.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      1\u001b[39m mitra = TabularPredictor(\n\u001b[32m      2\u001b[39m     label=\u001b[33m\"\u001b[39m\u001b[33mLabel\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      3\u001b[39m     problem_type=\u001b[33m\"\u001b[39m\u001b[33mbinary\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      4\u001b[39m     eval_metric=\u001b[33m\"\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      5\u001b[39m )\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43mmitra\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_dataset_smol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_cpus\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_gpus\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpresets\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmedium\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtime_limit\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m60\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhyperparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mMITRA\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mfine_tune\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mag_args_fit\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mnum_gpus\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m}\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/School/Fall 2025/CSCC11/Project/.venv/lib/python3.11/site-packages/autogluon/core/utils/decorators.py:31\u001b[39m, in \u001b[36munpack.<locals>._unpack_inner.<locals>._call\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(f)\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_call\u001b[39m(*args, **kwargs):\n\u001b[32m     30\u001b[39m     gargs, gkwargs = g(*other_args, *args, **kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mgargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mgkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/School/Fall 2025/CSCC11/Project/.venv/lib/python3.11/site-packages/autogluon/tabular/predictor/predictor.py:1363\u001b[39m, in \u001b[36mTabularPredictor.fit\u001b[39m\u001b[34m(self, train_data, tuning_data, time_limit, presets, hyperparameters, feature_metadata, infer_limit, infer_limit_batch_size, fit_weighted_ensemble, fit_full_last_level_weighted_ensemble, full_weighted_ensemble_additionally, dynamic_stacking, calibrate_decision_threshold, num_cpus, num_gpus, fit_strategy, memory_limit, callbacks, **kwargs)\u001b[39m\n\u001b[32m   1360\u001b[39m \u001b[38;5;66;03m# keep track of the fit strategy used for future calls\u001b[39;00m\n\u001b[32m   1361\u001b[39m \u001b[38;5;28mself\u001b[39m._fit_strategy = fit_strategy\n\u001b[32m-> \u001b[39m\u001b[32m1363\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag_fit_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mag_fit_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag_post_fit_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mag_post_fit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1365\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/School/Fall 2025/CSCC11/Project/.venv/lib/python3.11/site-packages/autogluon/tabular/predictor/predictor.py:1371\u001b[39m, in \u001b[36mTabularPredictor._fit\u001b[39m\u001b[34m(self, ag_fit_kwargs, ag_post_fit_kwargs)\u001b[39m\n\u001b[32m   1369\u001b[39m \u001b[38;5;28mself\u001b[39m._learner.fit(**ag_fit_kwargs)\n\u001b[32m   1370\u001b[39m \u001b[38;5;28mself\u001b[39m._set_post_fit_vars()\n\u001b[32m-> \u001b[39m\u001b[32m1371\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mag_post_fit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1372\u001b[39m \u001b[38;5;28mself\u001b[39m.save()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/School/Fall 2025/CSCC11/Project/.venv/lib/python3.11/site-packages/autogluon/tabular/predictor/predictor.py:1703\u001b[39m, in \u001b[36mTabularPredictor._post_fit\u001b[39m\u001b[34m(self, keep_only_best, refit_full, set_best_to_refit_full, save_space, calibrate, calibrate_decision_threshold, infer_limit, num_cpus, num_gpus, refit_full_kwargs, fit_strategy, raise_on_no_models_fitted)\u001b[39m\n\u001b[32m   1701\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model_names():\n\u001b[32m   1702\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m raise_on_no_models_fitted:\n\u001b[32m-> \u001b[39m\u001b[32m1703\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1704\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mNo models were trained successfully during fit().\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1705\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m Inspect the log output or increase verbosity to determine why no models were fit.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1706\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m Alternatively, set `raise_on_no_models_fitted` to False during the fit call.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1707\u001b[39m         )\n\u001b[32m   1709\u001b[39m     logger.log(\u001b[32m30\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mWarning: No models found, skipping post_fit logic...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1710\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: No models were trained successfully during fit(). Inspect the log output or increase verbosity to determine why no models were fit. Alternatively, set `raise_on_no_models_fitted` to False during the fit call."
     ]
    }
   ],
   "source": [
    "mitra = TabularPredictor(\n",
    "    label=\"Label\",\n",
    "    problem_type=\"binary\",\n",
    "    eval_metric=\"accuracy\",\n",
    ")\n",
    "mitra.fit(\n",
    "    train_data=train_dataset_smol,\n",
    "    num_cpus=1,\n",
    "    num_gpus=1,\n",
    "    presets=['medium'],\n",
    "    time_limit=60,\n",
    "    hyperparameters={\n",
    "        'MITRA': {\n",
    "            'fine_tune': False,\n",
    "            'ag_args_fit': {'num_gpus': 1}\n",
    "        }\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841b00f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
